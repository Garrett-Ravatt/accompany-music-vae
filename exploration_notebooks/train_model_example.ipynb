{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import magenta.music as mm\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "\n",
    "from data_utils.hdf5_sequence import HDF5Sequence\n",
    "from get_model import get_model\n",
    "from constants import MODEL_NAME, MODEL_SAVE_PATH, CHECKPOINT_PATH\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = 'hierdec-trio_16bar'\n",
    "config = configs.CONFIG_MAP[PRETRAINED_MODEL_NAME]\n",
    "\n",
    "DATA_PATH = './data/lmd_full/'\n",
    "HDF5_PATH = DATA_PATH + 'lmd_full_split.h5'\n",
    "\n",
    "# Definitions moved to get_model\n",
    "# TIMESTEPS = 256\n",
    "# DIM_MELODY = 90\n",
    "# DIM_LATENT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = h5py.File(HDF5_PATH, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = HDF5Sequence(data_file, batch_size, \n",
    "                         index_path=DATA_PATH + 'train_indices.csv')\n",
    "val_seq = HDF5Sequence(data_file, batch_size, \n",
    "                       index_path=DATA_PATH + 'val_indices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random hyperparam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "from constants import *\n",
    "\n",
    "ckpt_path_base = './models/checkpoints/bi_rnn_test_{}_{}/'\n",
    "model = None\n",
    "\n",
    "\n",
    "while True:\n",
    "    del model\n",
    "    \n",
    "    shape_1 = np.random.randint(16, 257)\n",
    "    shape_2 = np.random.randint(16, shape_1 + 1)\n",
    "            \n",
    "    ckpt_path = ckpt_path_base.format(shape_1, shape_2) + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(ckpt_path, monitor='val_loss', \n",
    "                                 verbose=1, save_best_only=False, mode='max')\n",
    "    logger = keras.callbacks.CSVLogger('./logs/brnn_{}_{}.log'.format(shape_1, shape_2))\n",
    "    callbacks_list = [checkpoint, logger]\n",
    "        \n",
    "    input_layer = KL.Input(shape=(TIMESTEPS, DIM_MELODY), name='input')\n",
    "    layer = KL.Bidirectional(\n",
    "        KL.CuDNNLSTM(shape_1, return_sequences=True, name='bi_lstm_1'))(input_layer)\n",
    "    layer = KL.Bidirectional(KL.CuDNNLSTM(shape_2, name='bi_lstm_2'))(layer)\n",
    "    output_layer = KL.Dense(DIM_LATENT, activation='linear', name='output')(layer)\n",
    "    model = KM.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.rmsprop(lr=3e-4),\n",
    "              loss='mean_squared_error')\n",
    "    \n",
    "    model.fit_generator(train_seq, steps_per_epoch=len(train_seq),\n",
    "                    validation_data=val_seq, validation_steps=len(val_seq),\n",
    "                    max_queue_size=128, workers=32, epochs=10,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = None\n",
    "del abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model: bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_1 = 128\n",
    "shape_2 = 128\n",
    "\n",
    "ckpt_path_base = './models/checkpoints/brnn_{}_{}/'\n",
    "ckpt_path = ckpt_path_base.format(shape_1, shape_2) + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(CHECKPOINT_PATH, monitor='val_loss', verbose=1, save_best_only=False, mode='max')\n",
    "logger = keras.callbacks.CSVLogger('./logs/brnn_{}_{}.log'.format(shape_1, shape_2))\n",
    "callbacks_list = [checkpoint, logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "from constants import *\n",
    "\n",
    "input_layer = KL.Input(shape=(TIMESTEPS, DIM_MELODY), name='input')\n",
    "layer = KL.Bidirectional(\n",
    "    KL.CuDNNLSTM(shape_1, return_sequences=True, name='bi_lstm_1'))(input_layer)\n",
    "layer = KL.Bidirectional(KL.CuDNNLSTM(shape_2, name='bi_lstm_2'))(layer)\n",
    "output_layer = KL.Dense(DIM_LATENT, activation='linear', name='output')(layer)\n",
    "model = KM.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.rmsprop(lr=3e-4),\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_seq, steps_per_epoch=len(train_seq),\n",
    "                    validation_data=val_seq, validation_steps=len(val_seq),\n",
    "                    max_queue_size=128, workers=32, epochs=20,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./models/checkpoints/brnn_128_128/03-0.1935.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 7\n",
    "batch = val_seq.__getitem__(0)\n",
    "notes, latents = batch\n",
    "notes = notes[which]\n",
    "latents = latents[which]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: in active dev. Use at your own risk.\n",
    "\n",
    "from copy import deepcopy\n",
    "from magenta.music.sequences_lib import concatenate_sequences\n",
    "\n",
    "midi = None\n",
    "# file = './data/lmd_clean/raw/Michael Jackson/Smooth Criminal.mid'\n",
    "file = './data/lmd_clean/raw/Simon & Garfunkel/Le Laureat: Mrs. Robinson.mid'\n",
    "# file = '/home/whillikers/dl/potter.mid'\n",
    "with open(file, 'rb') as midi_file:\n",
    "    midi = midi_file.read()\n",
    "    \n",
    "ns_full = mm.midi_to_sequence_proto(midi)\n",
    "\n",
    "# del ns_full.tempos[:]\n",
    "# del ns_full.time_signatures[:]\n",
    "# del ns_full.control_changes[:]\n",
    "# ns_full = utils.strip_to_melody(ns_full)\n",
    "# ns_melody = deepcopy(ns_full)\n",
    "\n",
    "# mm.plot_sequence(ns_full)\n",
    "# mm.play_sequence(ns_full, synth=mm.fluidsynth)\n",
    "\n",
    "# mel_tensor = config.data_converter._melody_converter.to_tensors(ns_full)\n",
    "# mel_tensor_2 = mel_tensor.outputs[0]\n",
    "# mel_tensor_2 = np.pad(mel_tensor_2, [(0, 256 - mel_tensor_2.shape[0]), (0, 0)], 'constant')\n",
    "# latents_pred = model.predict(np.expand_dims(mel_tensor_2[:256, :], 0))\n",
    "\n",
    "trio_tensors = config.data_converter.to_tensors(ns_full)[1]\n",
    "ns_trio = config.data_converter.to_notesequences(trio_tensors)[0]\n",
    "ns_melody = utils.strip_to_melody(ns_trio)\n",
    "\n",
    "mm.plot_sequence(ns_trio)\n",
    "mm.play_sequence(ns_trio, synth=mm.fluidsynth)\n",
    "\n",
    "melody_tensor = trio_tensors[0][:, :90]\n",
    "latents_pred = model.predict(np.expand_dims(melody_tensor, 0))[0]\n",
    "latents_pred = np.expand_dims(latents_pred, 0)\n",
    "\n",
    "ns_out = concatenate_sequences(\n",
    "    model_pretrained.decode(latents_pred, temperature=.1, length=64)\n",
    ")\n",
    "\n",
    "ns_stitch = utils.remove_melody(ns_out)\n",
    "ns_stitch.notes.extend(ns_melody.notes)\n",
    "# ns_stitch = ns_out\n",
    "\n",
    "mm.plot_sequence(ns_stitch)\n",
    "mm.play_sequence(ns_stitch, synth=mm.fluidsynth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_tensor_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_tensor_2 = mel_tensor.outputs[0]\n",
    "mel_tensor_2 = np.pad(mel_tensor_2, [(0, 256 - mel_tensor_2.shape[0]), (0, 0)], 'constant')\n",
    "mel_tensor_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from magenta.\n",
    "\n",
    "configs.CONFIG_MAP['hierdec-mel_16bar'].data_converter._to_tensors(ns_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_tensor.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_tensor = config.data_converter._melody_converter.to_tensors(ns_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_tensor[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(config.data_converter.to_tensors(ns_full).outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(config.data_converter.to_notesequences(trio_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = config.data_converter.to_notesequences(trio_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained = TrainedModel(\n",
    "    config, batch_size=batch_size,\n",
    "    checkpoint_dir_or_path='./models/pretrained/{}.ckpt'.format(\n",
    "        PRETRAINED_MODEL_NAME))\n",
    "\n",
    "ns = config.data_converter._melody_converter.to_notesequences(np.expand_dims(notes, 0))\n",
    "mm.plot_sequence(ns[0])\n",
    "mm.play_sequence(ns[0], synth=mm.fluidsynth)\n",
    "\n",
    "latents_pred = model.predict(np.expand_dims(notes, 0))[0]\n",
    "\n",
    "ns_out = model_pretrained.decode([latents, latents_pred],\n",
    "                                 temperature=0.1, length=64)\n",
    "ns_true = ns_out[0]\n",
    "ns_infer = ns_out[1]\n",
    "\n",
    "ns_stitch = utils.remove_melody(ns_out[1])\n",
    "ns_stitch.notes.extend(ns[0].notes)\n",
    "\n",
    "mm.plot_sequence(ns_true)\n",
    "mm.play_sequence(ns_true, synth=mm.fluidsynth)\n",
    "\n",
    "mm.plot_sequence(ns_infer)\n",
    "mm.play_sequence(ns_infer, synth=mm.fluidsynth)\n",
    "\n",
    "mm.plot_sequence(ns_stitch)\n",
    "mm.play_sequence(ns_stitch, synth=mm.fluidsynth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
