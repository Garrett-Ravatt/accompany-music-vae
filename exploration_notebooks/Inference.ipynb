{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import magenta.music as mm\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "from magenta.music.sequences_lib import concatenate_sequences\n",
    "\n",
    "from utils import strip_to_melody, remove_melody\n",
    "from get_model import get_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(midi_input, melody_model, trio_model, config, use_original_melody=True):\n",
    "    '''\n",
    "        midi_input:   the read in midi file (i.e. midi_file.read())\n",
    "        melody_model: Our model that takes a melody and predicts the latent space encoding\n",
    "        trio_model:   The magenta trio model that we are using to decode the latent vector\n",
    "        config:       Used for data conversions. \n",
    "                      Can get by e.g. config = configs.CONFIG_MAP[model_name]\n",
    "                      Might be able to just use the config in trio_model? Unsure.\n",
    "    '''\n",
    "    # Convert the midi to a NoteSequence\n",
    "    input_note_seq = mm.midi_to_sequence_proto(midi_input)\n",
    "    # mm.midi_to_sequence_proto(midi_file.read())\n",
    "    \n",
    "    # Convert the sequence to tensors, and then strip out just the melody.\n",
    "    trio_tensors  = config.data_converter.to_tensors(input_note_seq).outputs\n",
    "    \n",
    "    # TODO: is this filter necessary? What does it do?\n",
    "#     trio_tensors  = trio_tensors = list(\n",
    "#                         filter(lambda t: t.shape == (TIMESTEPS, DIM_TRIO),\n",
    "#                                trio_tensors)\n",
    "#                     )\n",
    "    melody_tensors = np.array(list(map(lambda t: t[:, :DIM_MELODY],\n",
    "                                       trio_tensors)))\n",
    "    \n",
    "\n",
    "    # Get the latent representation of just the melody using our trained model\n",
    "    latent_code = melody_model.predict(melody_tensors)\n",
    "    \n",
    "    # Decode the latent representation of the melody into 3 parts using Trio\n",
    "    # Note that this returns an array of different, related musical sections.\n",
    "    # We use concatenate_sequences to combine them all into one longer piece.\n",
    "    output_trio_seq = concatenate_sequences(trio_model.decode(latent_code))\n",
    "    \n",
    "    if not use_original_melody:\n",
    "        return output_trio_seq\n",
    "\n",
    "    # Slice in the orignal melody\n",
    "    \n",
    "    # Take out only the generated accompaniment\n",
    "    # TODO: Does\n",
    "    non_melody_seq = remove_melody(output_trio_seq)\n",
    "    \n",
    "    # Stitch the original melody and the new accompaniment together.\n",
    "    recombined_seq = strip_to_melody(input_note_seq)\n",
    "    non_melody_seq.MergeFrom(recombined_seq)\n",
    "    return non_melody_seq\n",
    "#     recombined_seq.MergeFrom(non_melody_seq)\n",
    "#     return recombined_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Inference\n",
    "\n",
    "## Parameter Setup \n",
    "\n",
    "### Trio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_melody_2bar  = 'cat-mel_2bar_big'\n",
    "model_name_melody_16bar = 'hierdec-mel_16bar'\n",
    "model_name_trio_16bar   = 'hierdec-trio_16bar'\n",
    "\n",
    "model_name = model_name_trio_16bar\n",
    "config = configs.CONFIG_MAP[model_name]\n",
    "\n",
    "trio_model = TrainedModel(config,\n",
    "                     batch_size=16,\n",
    "                     checkpoint_dir_or_path='./models/pretrained/{}.ckpt'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = None\n",
    "with open('./data/lmd_clean/Toto/Africa.3.mid', 'rb') as midi_file:\n",
    "    midi = midi_file.read()\n",
    "input_note_seq = mm.midi_to_sequence_proto(midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Melody Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melody_model = get_model()\n",
    "melody_model.load_weights(\"./models/checkpoints/bi_rnn_test/01-0.0682.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_seq = inference(midi, melody_model, trio_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.play_sequence(input_note_seq, synth=mm.fluidsynth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.play_sequence(generated_seq, synth=mm.fluidsynth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_note_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
